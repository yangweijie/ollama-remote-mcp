#!/usr/bin/env node
import { McpServer } from "@modelcontextprotocol/sdk/server/mcp.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import { z } from "zod";
// å·¥å…·å‡½æ•°ï¼šæ ¼å¼åŒ–æ–‡ä»¶å¤§å°
function formatSize(bytes) {
    if (bytes === 0)
        return '0 B';
    const k = 1024;
    const sizes = ['B', 'KB', 'MB', 'GB', 'TB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(1)) + ' ' + sizes[i];
}
// 1. è·å–é…ç½® (ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡)
// åœ¨ Claude Desktop é…ç½®æ–‡ä»¶ä¸­é€šè¿‡ env ä¼ å…¥
const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || "http://localhost:11434";
const OLLAMA_API_KEY = process.env.OLLAMA_API_KEY || "";
// åˆ›å»º MCP æœåŠ¡å™¨å®ä¾‹
const server = new McpServer({
    name: "remote-ollama-mcp",
    version: "1.0.0",
});
// 2. å®šä¹‰å·¥å…·ï¼šè®© Claude å¯ä»¥è°ƒç”¨è¿œç¨‹ Ollama æ¨¡å‹
// 2.1 å·¥å…·ï¼šåˆ—å‡ºå¯ç”¨çš„ Ollama æ¨¡å‹
server.tool("list_ollama_models", "åˆ—å‡ºè¿œç¨‹ Ollama æœåŠ¡å™¨ä¸Šæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹", {
    only_remote: z.boolean().optional().default(false).describe("åªæ˜¾ç¤ºäº‘ç«¯æ¨¡å‹ä¿¡æ¯ï¼Œé»˜è®¤æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹")
}, async ({ only_remote }) => {
    try {
        // æ„å»ºè¯·æ±‚ URL
        const url = `${OLLAMA_BASE_URL.replace(/\/$/, "")}/api/tags`;
        // æ„å»ºè¯·æ±‚å¤´
        const headers = {
            "Content-Type": "application/json",
        };
        // å¦‚æœé…ç½®äº† API Keyï¼Œæ·»åŠ åˆ° Authorization Header
        if (OLLAMA_API_KEY) {
            headers["Authorization"] = `Bearer ${OLLAMA_API_KEY}`;
        }
        // å‘é€è¯·æ±‚è·å–æ¨¡å‹åˆ—è¡¨
        const response = await fetch(url, {
            method: "GET",
            headers,
        });
        if (!response.ok) {
            return {
                content: [
                    {
                        type: "text",
                        text: `Error: Ollama API responded with status ${response.status}: ${response.statusText}`,
                    },
                ],
                isError: true,
            };
        }
        const data = await response.json();
        const models = data.models || [];
        if (models.length === 0) {
            return {
                content: [
                    {
                        type: "text",
                        text: "å½“å‰ Ollama æœåŠ¡å™¨ä¸Šæ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ã€‚\n\næ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–æ¨¡å‹ï¼š\n1. æœ¬åœ°æ¨¡å‹ï¼šä½¿ç”¨ `ollama pull <æ¨¡å‹å>` ä¸‹è½½æ¨¡å‹\n2. äº‘ç«¯æ¨¡å‹ï¼šé…ç½® Ollama Cloud è´¦æˆ·æˆ–ä»£ç†æœåŠ¡",
                    },
                ],
            };
        }
        // æ ¼å¼åŒ–æ¨¡å‹åˆ—è¡¨
        const modelList = models.map((model) => {
            const name = model.name;
            const size = model.size;
            const modifiedAt = model.modified_at;
            // æ£€æµ‹æ˜¯å¦ä¸ºäº‘ç«¯æ¨¡å‹ï¼ˆä¸€èˆ¬äº‘ç«¯æ¨¡å‹ä¼šæœ‰ç‰¹å®šçš„å‘½åæ¨¡å¼ï¼‰
            const isRemoteModel = name.includes('cloud') ||
                name.includes('online') ||
                name.includes('api') ||
                name.includes('remote') ||
                name.includes('llama3') && name.includes(':') === false;
            return {
                name,
                size: formatSize(size),
                modifiedAt,
                isRemoteModel
            };
        });
        // å¦‚æœåªæ˜¾ç¤ºäº‘ç«¯æ¨¡å‹ï¼Œè¿‡æ»¤ç»“æœ
        const filteredModels = only_remote
            ? modelList.filter((model) => model.isRemoteModel)
            : modelList;
        const displayModels = filteredModels.length > 0 ? filteredModels : modelList;
        // ç”Ÿæˆæ ¼å¼åŒ–è¾“å‡º
        const modelListText = displayModels.map((model, index) => {
            const prefix = model.isRemoteModel ? "â˜ï¸ äº‘ç«¯" : "ğŸ’¾ æœ¬åœ°";
            return `${index + 1}. **${prefix}** ${model.name}\n   - å¤§å°: ${model.size}\n   - æ›´æ–°æ—¶é—´: ${model.modifiedAt}`;
        }).join('\n\n');
        const summary = `ğŸ¤– Ollama æ¨¡å‹åˆ—è¡¨\n\næ€»å…±æœ‰ ${models.length} ä¸ªå¯ç”¨æ¨¡å‹${only_remote ? ' (ä»…æ˜¾ç¤ºäº‘ç«¯æ¨¡å‹)' : ''}:\n\n${modelListText}`;
        return {
            content: [
                {
                    type: "text",
                    text: summary,
                },
            ],
        };
    }
    catch (error) {
        return {
            content: [
                {
                    type: "text",
                    text: `è¿æ¥å¤±è´¥: ${error.message}ã€‚è¯·æ£€æŸ¥æ‚¨çš„ OLLAMA_BASE_URL å’Œç½‘ç»œè¿æ¥ã€‚`,
                },
            ],
            isError: true,
        };
    }
});
// 2.2 å·¥å…·ï¼šå‘è¿œç¨‹ Ollama å‘é€å¯¹è¯è¯·æ±‚
server.tool("chat_with_remote_ollama", "å‘è¿œç¨‹ Ollama æœåŠ¡å™¨å‘é€å¯¹è¯è¯·æ±‚ï¼Œæ”¯æŒè‡ªå®šä¹‰æ¨¡å‹", {
    model: z.string().describe("è¦ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ 'llama3', 'deepseek-coder'"),
    message: z.string().describe("å‘é€ç»™æ¨¡å‹çš„æç¤ºè¯æˆ–é—®é¢˜"),
    system_prompt: z.string().optional().describe("å¯é€‰çš„ç³»ç»Ÿçº§æŒ‡ä»¤"),
    temperature: z.number().optional().default(0.7).describe("æ¨¡å‹æ¸©åº¦ï¼Œ0-1ä¹‹é—´")
}, async ({ model, message, system_prompt, temperature }) => {
    try {
        // æ„å»ºè¯·æ±‚ URL
        const url = `${OLLAMA_BASE_URL.replace(/\/$/, "")}/v1/chat/completions`;
        // æ„å»ºè¯·æ±‚å¤´
        const headers = {
            "Content-Type": "application/json",
        };
        // å¦‚æœé…ç½®äº† API Keyï¼Œæ·»åŠ åˆ° Authorization Header
        // é€‚é…å¤§å¤šæ•° Nginx Bearer Auth æˆ–è‡ªå®šä¹‰ Auth
        if (OLLAMA_API_KEY) {
            headers["Authorization"] = `Bearer ${OLLAMA_API_KEY}`;
        }
        // æ„å»ºè¯·æ±‚ä½“
        const body = {
            model: model,
            messages: [
                ...(system_prompt ? [{ role: "system", content: system_prompt }] : []),
                { role: "user", content: message }
            ],
            stream: false, // MCP å·¥å…·é€šå¸¸éœ€è¦ä¸€æ¬¡æ€§è¿”å›ç»“æœï¼Œå…³é—­æµå¼ä¼ è¾“
            options: {
                temperature: temperature
            }
        };
        // å‘é€è¯·æ±‚
        const response = await fetch(url, {
            method: "POST",
            headers,
            body: JSON.stringify(body),
        });
        if (!response.ok) {
            return {
                content: [
                    {
                        type: "text",
                        text: `Error: Ollama API responded with status ${response.status}: ${response.statusText}`,
                    },
                ],
                isError: true,
            };
        }
        const data = await response.json();
        const reply = data.choices?.[0]?.message?.content || "No content returned";
        console.error('[MCP DEBUG] Extracted reply:', reply);
        return {
            content: [
                {
                    type: "text",
                    text: reply,
                },
            ],
        };
    }
    catch (error) {
        return {
            content: [
                {
                    type: "text",
                    text: `Connection Failed: ${error.message}. Please check your OLLAMA_BASE_URL and connectivity.`,
                },
            ],
            isError: true,
        };
    }
});
// 3. å¯åŠ¨æœåŠ¡å™¨
async function main() {
    const transport = new StdioServerTransport();
    await server.connect(transport);
    console.error("Remote Ollama MCP Server running on stdio");
}
main().catch((error) => {
    console.error("Fatal error in main():", error);
    process.exit(1);
});
